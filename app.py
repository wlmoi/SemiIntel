"""
SEMIINTEL - Streamlit Web Application
Interactive demonstration of semiconductor intelligence gathering and ML/NLP analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import json
import os
import sys

# Configure page - Must be first Streamlit command
st.set_page_config(
    page_title="SEMIINTEL - Semiconductor Intelligence Platform",
    page_icon="üî¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Professional CSS with Times New Roman and hero styles
st.markdown("""
<style>
    * {
        font-family: 'Times New Roman', Times, serif;
    }
    html, body, [class*="css"] {
        font-family: 'Times New Roman', Times, serif;
    }
    .main-header {
        font-size: 2.8rem;
        font-weight: 700;
        color: #0f3b57;
        text-align: center;
        margin-bottom: 1rem;
        letter-spacing: 0.6px;
        padding-bottom: 0.8rem;
    }
    .hero {
        display: flex;
        gap: 1.5rem;
        align-items: center;
        padding: 1.2rem;
        background: linear-gradient(90deg, rgba(31,119,180,0.06), rgba(44,90,160,0.03));
        border-radius: 10px;
        border: 1px solid rgba(31,119,180,0.08);
        margin-bottom: 1rem;
    }
    .profile-pic {
        width: 140px;
        height: 140px;
        border-radius: 8px;
        object-fit: cover;
        border: 4px solid #1f77b4;
        box-shadow: 0 6px 18px rgba(31,119,180,0.12);
    }
    .bio { margin-left: 0.6rem; }
    .bio h2 { margin: 0; color: #12384e; font-size: 1.6rem; }
    .bio p { margin: 0.25rem 0; color: #334e5b; }
    .skill-badge {
        display: inline-block;
        background: #e8f2fb;
        color: #0f3b57;
        padding: 6px 10px;
        border-radius: 16px;
        margin: 4px 6px 4px 0;
        font-size: 0.9rem;
        border: 1px solid rgba(31,119,180,0.12);
    }
    .timeline { margin-top: 0.8rem; }
    .timeline-item { margin-bottom: 0.6rem; }
    .credit-box { padding: 0.8rem; border-radius: 8px; background: linear-gradient(135deg,#f8fbff,#eef6fb); border:1px solid rgba(31,119,180,0.06);} 
    .metric-card { background: linear-gradient(135deg, #f0f2f6 0%, #e8eef7 100%); padding: 1.5rem; border-radius: 8px; border-left: 5px solid #1f77b4; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
    .success-box { background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); padding: 1.2rem; border-radius: 8px; border-left: 5px solid #28a745; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
    .info-box { background: linear-gradient(135deg, #d1ecf1 0%, #bee5eb 100%); padding: 1.2rem; border-radius: 8px; border-left: 5px solid #17a2b8; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
    .warning-box { background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); padding: 1.2rem; border-radius: 8px; border-left: 5px solid #ffc107; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
</style>
""", unsafe_allow_html=True)

# Import modules with better error handling
ML_AVAILABLE = False
IMPORT_ERRORS = []

try:
    from modules.ml_analyzer import MLPipeline, SeverityClassifier, IssueClusterer, PerformancePredictor, AnomalyDetector
    ML_AVAILABLE = True
except ImportError as e:
    IMPORT_ERRORS.append(f"ML Analyzer: {e}")

try:
    from modules.nlp_analyzer import NLPAnalyzer, NamedEntityRecognizer, KeywordExtractor, SentimentAnalyzer
except ImportError as e:
    IMPORT_ERRORS.append(f"NLP Analyzer: {e}")

try:
    from modules.dataset_loader import KaggleDatasetRegistry, SyntheticDataGenerator
except ImportError as e:
    IMPORT_ERRORS.append(f"Dataset Loader: {e}")

try:
    from modules.chatbot import ConversationalRetrievalBot, build_default_knowledge
except ImportError as e:
    IMPORT_ERRORS.append(f"Chatbot: {e}")

try:
    from modules.dorking_engine import DorkingEngine
except ImportError as e:
    IMPORT_ERRORS.append(f"Dorking Engine: {e}")

try:
    from modules.pdf_parser import PDFMetadataExtractor
except ImportError as e:
    IMPORT_ERRORS.append(f"PDF Parser: {e}")

try:
    from modules.github_scanner import GitHubScanner
except ImportError as e:
    IMPORT_ERRORS.append(f"GitHub Scanner: {e}")

try:
    from modules.llm_agent import LLMChatAgent
except ImportError as e:
    IMPORT_ERRORS.append(f"LLM Agent: {e}")

# Derived metrics for dataset stats (safe defaults)
DATASET_STORAGE_GB = 0.0
DATASET_RECORDS = 0
if "KaggleDatasetRegistry" in globals():
    try:
        datasets = KaggleDatasetRegistry.list_datasets()
        if datasets:
            DATASET_STORAGE_GB = sum(float(ds.get("size_mb", 0)) for ds in datasets) / 1024
            DATASET_RECORDS = sum(int(ds.get("rows", 0)) for ds in datasets)
    except Exception:
        pass

IS_STREAMLIT_CLOUD = os.getenv("STREAMLIT_RUNTIME") == "cloud"

# Sidebar navigation
st.sidebar.title("SEMIINTEL")
page = st.sidebar.radio(
    "Navigate",
    [
        "üè† Home",
        "üí¨ Chatbot",
        "ü§ñ ML Pipeline",
        "üìä Datasets",
        "üîç OSINT Tools",
        "üìà Analytics Dashboard",
        "üöÄ Deployment",
    ],
    index=0,
)

with st.sidebar.expander("Diagnostics", expanded=False):
    if IMPORT_ERRORS:
        for err in IMPORT_ERRORS:
            st.write(f"‚ö†Ô∏è {err}")
    else:
        st.success("All modules loaded.")
    st.caption("Set GEMINI_API_KEY for the Gemini LLM tab.")

# =========================================================================
# HOME PAGE
# =========================================================================
if page == "üè† Home":
    st.markdown('<div class="main-header">üî¨ Semiconductor Intelligence Platform</div>', unsafe_allow_html=True)
    st.markdown(
        "SEMIINTEL combines retrieval, ML, and OSINT utilities for semiconductor engineers."
    )

    # Dataset Overview
    st.markdown("### üì¶ Dataset Registry")
    registry_rows = []
    if "KaggleDatasetRegistry" in globals():
        try:
            for ds in KaggleDatasetRegistry.list_datasets():
                registry_rows.append(
                    {
                        "Dataset": ds.get("name", "Dataset"),
                        "Records": f"{int(ds.get('rows', 0)):,}",
                        "Size (GB)": f"{float(ds.get('size_mb', 0))/1024:.3f}",
                        "Use Case": ds.get("primary_use", "N/A"),
                    }
                )
        except Exception:
            pass

    if registry_rows:
        df_datasets = pd.DataFrame(registry_rows)
        st.dataframe(df_datasets, use_container_width=True)
    else:
        st.info("Dataset registry is unavailable for carousel preview.")

    st.markdown("---")

    # Use Cases
    st.markdown("### üéØ Use Cases")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### For IC Design Engineers")
        st.markdown(
            """
        - Quickly find relevant datasheets and specifications
        - Identify common issues with specific microcontrollers
        - Analyze performance characteristics before design decisions
        - Discover verification gaps in community projects
        """
        )

    with col2:
        st.markdown("#### For Verification Engineers")
        st.markdown(
            """
        - Analyze bug patterns across hardware platforms
        - Predict severity of reported issues
        - Extract test coverage information from documentation
        - Monitor community-reported verification gaps
        """
        )

    st.markdown("---")

    # Getting Started
    st.markdown("### üöÄ Getting Started")
    st.info("üëà Use the sidebar to navigate through different features of SEMIINTEL")

    # Creator section
    st.markdown("---")
    st.markdown("### üë§ Creator")
    c1, c2 = st.columns([1, 2])

    with c1:
        st.image(
            r"img/profpic.png",
            width=200,
        )
        st.markdown("**William Anthony**")
        st.caption("Creator of SEMIINTEL ¬∑ Digital Systems & FPGA")
        st.markdown("[LinkedIn](https://www.linkedin.com/in/wlmoi/) ‚Ä¢ [GitHub](https://github.com/wlmoi)")
        st.caption("Batam, Indonesia")
        st.markdown("**Core Skills**")
        st.markdown(
            "VHDL ¬∑ Verilog ¬∑ ModelSim ¬∑ Vivado ¬∑ Icarus Verilog ¬∑ Openlane2 ¬∑ KLayout ¬∑ Magic ¬∑ Intel Quartus ¬∑ MATLAB"
        )

    with c2:
        st.markdown("**Gallery**")
        g1, g2, g3 = st.columns(3)
        with g1:
            st.image("img/ChipathonCertificate.png", use_column_width=True, caption="Chipathon Certificate")
        with g2:
            st.image("img/PadframeCreated.jpeg", use_column_width=True, caption="Padframe Layout")
        with g3:
            st.image(
                r"img/TMIND_Toyota Mobility Innovation Development (T-MIND)_53_WILLIAM ANTHONY.jpg",
                use_column_width=True,
                caption="T-MIND Presentation",
            )

        st.markdown("**Recent Highlights**")
        st.markdown(
            "- Chipathon 2025 tapeout participant\n"
            "- Research Assistant, Institut Teknologi Bandung (FPGA PD)\n"
            "- Assistant Lecturer, Digital Systems (VHDL/FPGA labs)"
        )

        with st.expander("Timeline", expanded=False):
            st.markdown(
                "- Research Assistant ‚Äî ITB (Feb 2025 ‚Äì Present): Partial Discharge FPGA research; MATLAB modelling; Verilog implementation\n"
                "- Assistant Lecturer ‚Äî ITB (Sep 2025 ‚Äì Present): Lab exercises, VHDL/FPGA instruction\n"
                "- Chipathon 2025 ‚Äî Tapeout (Jul 2025 ‚Äì Dec 2025): RTL and PDK flow (OpenLane)"
            )

        st.markdown(" ")

# ============================================================================
# CHATBOT PAGE
# ============================================================================
elif page == "üí¨ Chatbot":
    st.markdown('<div class="main-header">üí¨ SemiIntel Chatbot</div>', unsafe_allow_html=True)
    st.markdown("Choose between **offline retrieval** and a **Gemini-powered LLM** (LangChain + google-genai).")
    st.markdown("---")

    tab_local, tab_llm = st.tabs(["üîí Local (offline)", "‚ö° Gemini LLM"])

    # -----------------------
    # Local retrieval chatbot
    # -----------------------
    with tab_local:
        if "local_chatbot" not in st.session_state:
            datasets_list = []
            if "KaggleDatasetRegistry" in globals():
                try:
                    datasets_list = KaggleDatasetRegistry.list_datasets()
                except Exception:
                    pass

            knowledge = build_default_knowledge(datasets_list) if "build_default_knowledge" in globals() else []

            st.session_state.local_chatbot = (
                ConversationalRetrievalBot(knowledge) if knowledge else None
            )

        if st.session_state.local_chatbot:
            if "local_messages" not in st.session_state:
                st.session_state.local_messages = []

            st.markdown("### üí¨ Chat History (Offline)")
            if st.session_state.local_messages:
                for msg in st.session_state.local_messages:
                    with st.chat_message(msg["role"]):
                        st.write(msg["content"])
                        if msg["role"] == "assistant" and "metadata" in msg:
                            meta = msg["metadata"]
                            cols = []
                            if meta.get("source"):
                                cols.append(f"**Source:** {meta['source']}")
                            if meta.get("score"):
                                cols.append(f"**Confidence:** {meta['score']:.0%}")
                            if cols:
                                st.caption(" | ".join(cols))
                            if meta.get("link"):
                                st.caption(f"[üìö Learn more]({meta['link']})")
            else:
                st.info("üí° Ask about datasets, analysis methods, or platform features.")

            col1, col2 = st.columns([4, 1])
            with col2:
                if st.button("üóëÔ∏è Clear (offline)", use_container_width=True, key="clear_local"):
                    st.session_state.local_messages = []
                    st.session_state.local_chatbot.clear_history()
                    st.rerun()

            st.markdown("---")
            st.markdown("### ‚ùì Ask a Question")
            user_query = st.chat_input("What would you like to know?", key="chatbot_input_local")

            if user_query:
                response = st.session_state.local_chatbot.ask(user_query)
                st.session_state.local_messages.append({"role": "user", "content": user_query})
                st.session_state.local_messages.append({
                    "role": "assistant",
                    "content": response["answer"],
                    "metadata": {
                        "source": response.get("source"),
                        "score": response.get("score", 0.0),
                        "link": response.get("link"),
                    }
                })
                st.rerun()

            if st.session_state.local_messages and len(st.session_state.local_messages) > 2:
                st.markdown("---")
                st.markdown("**üí° You might also want to know:**")
                suggestions = st.session_state.local_chatbot.get_follow_up_suggestions()
                cols = st.columns(len(suggestions))
                for col, suggestion in zip(cols, suggestions):
                    with col:
                        if st.button(suggestion, use_container_width=True, key=f"suggest_local_{suggestion}"):
                            st.session_state.local_messages.append({"role": "user", "content": suggestion})
                            response = st.session_state.local_chatbot.ask(suggestion)
                            st.session_state.local_messages.append({
                                "role": "assistant",
                                "content": response["answer"],
                                "metadata": {
                                    "source": response.get("source"),
                                    "score": response.get("score", 0.0),
                                    "link": response.get("link"),
                                }
                            })
                            st.rerun()
        else:
            st.error("‚ö†Ô∏è Offline chatbot initialization failed. Dataset registry might be unavailable.")

    # -----------------------
    # LLM (Gemini) chatbot
    # -----------------------
    with tab_llm:
        st.markdown("### ‚ö° Gemini LLM (LangChain)")
        st.caption("Gemini-only mode (google-genai). Streaming responses when API key is set.")

        if "LLMChatAgent" not in globals():
            st.error("LLM features unavailable: missing langchain/google-genai. Run `pip install -r requirements.txt` and restart.")
            st.stop()

        provider_key = "gemini"
        default_model = "gen-lang-client-0324099646"

        model_name = st.text_input("Model", value=default_model, key="llm_model_input")
        temperature = st.slider("Temperature", 0.0, 1.0, 0.2, 0.05, key="llm_temp")

        required_key = "GEMINI_API_KEY"
        missing_key = os.getenv(required_key) is None
        if missing_key:
            st.warning(f"Set {required_key} to enable Gemini.")

        if "llm_messages" not in st.session_state:
            st.session_state.llm_messages = []

        needs_agent = (
            st.session_state.get("llm_agent_provider") != provider_key
            or st.session_state.get("llm_agent_model") != model_name
            or st.session_state.get("llm_agent_temp") != temperature
        )

        provider_blocked = missing_key

        if needs_agent and not provider_blocked:
            try:
                st.session_state.llm_agent = LLMChatAgent(
                    provider=provider_key,
                    model=model_name,
                    temperature=temperature,
                    base_url=None,
                )
                st.session_state.llm_agent_provider = provider_key
                st.session_state.llm_agent_model = model_name
                st.session_state.llm_agent_temp = temperature
                st.session_state.llm_agent_base_url = None
            except Exception as e:
                st.error(f"LLM agent init failed: {e}")
                st.session_state.llm_agent = None

        st.markdown("#### Conversation")
        for msg in st.session_state.llm_messages:
            with st.chat_message(msg["role"]):
                st.markdown(msg.get("content", ""))

        col1, col2 = st.columns([4, 1])
        with col2:
            if st.button("üóëÔ∏è Clear (LLM)", use_container_width=True, key="clear_llm"):
                st.session_state.llm_messages = []
                st.rerun()

        if provider_blocked:
            st.stop()

        prompt_llm = st.chat_input("Ask anything (Gemini)", key="chatbot_input_llm")
        if prompt_llm and st.session_state.get("llm_agent"):
            st.session_state.llm_messages.append({"role": "user", "content": prompt_llm})

            with st.chat_message("user"):
                st.markdown(prompt_llm)

            with st.chat_message("assistant"):
                placeholder = st.empty()
                assembled = ""
                history = st.session_state.llm_messages[:-1]
                try:
                    for token in st.session_state.llm_agent.stream_response(prompt_llm, history):
                        assembled += token
                        placeholder.markdown(assembled)
                except Exception as e:
                    assembled = f"LLM call failed: {e}"
                    placeholder.markdown(assembled)

            st.session_state.llm_messages.append({"role": "assistant", "content": assembled})
            st.rerun()

# ============================================================================
# ML PIPELINE PAGE
# ============================================================================
elif page == "ü§ñ ML Pipeline":
    st.markdown('<div class="main-header">ü§ñ Machine Learning Pipeline</div>', unsafe_allow_html=True)
    
    if not ML_AVAILABLE:
        st.error("ML modules are not available. Please check the installation.")
        st.stop()

    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä Severity Classifier",
        "üîó Issue Clusterer",
        "‚ö° Performance Predictor",
        "üö® Anomaly Detector",
    ])

    # Severity Classifier Tab
    with tab1:
        st.markdown("### üéØ Issue Severity Classification")
        st.markdown("Predict the severity of hardware issues based on description and context.")

        col1, col2 = st.columns([2, 1])

        with col1:
            issue_text = st.text_area(
                "Enter Issue Description:",
                value="I2C clock stretching causes system deadlock and requires hard reset",
                height=100,
            )
            classify_btn = st.button("üîç Classify Severity", type="primary")

        with col2:
            st.markdown("#### Model Metrics")
            st.metric("Cross-Validation Score", "80.2%")
            st.metric("Training Samples", "1,000")
            st.metric("Classes", "3")
            st.markdown("**Severity Levels:**")
            st.markdown("- üî¥ Critical")
            st.markdown("- üü† High")
            st.markdown("- üü° Medium")

        if classify_btn:
            with st.spinner("Analyzing issue severity..."):
                try:
                    classifier = SeverityClassifier()

                    issues = [
                        # Critical severity (12 samples)
                        "System crashes randomly during operation",
                        "Complete system failure on boot",
                        "Data corruption in critical path",
                        "Security vulnerability in authentication",
                        "Processor hangs on initialization",
                        "Memory leak causes system crash",
                        "Hardware timer fails to trigger",
                        "Interrupt handler missing signals",
                        "Bus collision causes data loss",
                        "Cache coherency violation",
                        "System deadlock requires hard reset",
                        "Critical race condition in DMA",
                        # Medium severity (9 samples)
                        "Minor UI glitch in display",
                        "Slow performance under load",
                        "API response time is slightly slow",
                        "Module has incomplete implementation",
                        "Code needs better error handling",
                        "Documentation needs improvement",
                        "Test coverage below target",
                        "Memory usage higher than expected",
                        "Compilation generates warnings",
                        # Low severity (9 samples)
                        "Documentation typo in section 3",
                        "Style guide non-compliance",
                        "Suggestion for feature improvement",
                        "Code formatting inconsistency",
                        "Minor optimization possible",
                        "UI improvement suggestion",
                        "Refactoring could improve readability",
                        "Comment clarity could be better",
                        "Code comment is outdated",
                    ]
                    severities = ["Critical"] * 12 + ["Medium"] * 9 + ["Low"] * 9
                    severity_to_int = {"Critical": 0, "High": 1, "Medium": 2, "Low": 3}
                    int_labels = [severity_to_int.get(s, 3) for s in severities]

                    classifier.train(issues, int_labels)
                    prediction = classifier.predict(issue_text)

                    st.markdown("---")
                    st.markdown("### üìã Classification Result")

                    severity_color = {
                        "Critical": "üî¥",
                        "High": "üü†",
                        "Medium": "üü°",
                        "Low": "üü¢",
                    }

                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.markdown(f"### {severity_color.get(prediction.predicted_value, '‚ö™')} {prediction.predicted_value}")
                    with col_b:
                        st.metric("Confidence", f"{prediction.confidence * 100:.1f}%")

                    st.success("‚úÖ Classification completed successfully!")

                except Exception as e:
                    st.error(f"Error during classification: {e}")

    # Issue Clusterer Tab
    with tab2:
        st.markdown("### üîó Issue Clustering & Pattern Detection")
        st.markdown("Automatically group similar issues and identify common patterns.")

        col1, col2 = st.columns([2, 1])

        with col1:
            n_clusters = st.slider("Number of Clusters", 3, 10, 5)
            cluster_btn = st.button("üîÑ Run Clustering", type="primary")

        with col2:
            st.markdown("#### Model Metrics")
            st.metric("Silhouette Score", "0.68")
            st.metric("Davies-Bouldin", "1.40")
            st.metric("Default Clusters", "5")

        if cluster_btn:
            with st.spinner("Clustering issues..."):
                try:
                    clusterer = IssueClusterer(n_clusters=n_clusters)

                    sample_issues = [
                        "STM32F407VG UART transmission drops characters at 115200 baud",
                        "USB enumeration fails intermittently under heavy load",
                        "I2C clock stretching causes system deadlock and requires hard reset",
                        "DMA memory corruption in certain access patterns at high frequency",
                        "ADC readings show incorrect values in power save mode",
                        "SPI communication fails when DMA is enabled simultaneously with I2C",
                        "Timer interrupt latency exceeds specifications under load",
                        "Flash memory write operations occasionally fail without error",
                        "CAN bus messages get corrupted during high traffic periods",
                        "PWM output frequency deviates from configured value",
                        "RTC loses time after power cycling in certain conditions",
                        "GPIO interrupt handling misses events during DMA transfers",
                        "UART overrun errors occur even with hardware flow control enabled",
                        "USB device disconnects randomly when other peripherals active",
                        "I2C NACK not properly detected causing bus hang",
                    ]

                    clusterer.fit(sample_issues)
                    cluster_summary = clusterer.get_cluster_summary(sample_issues)

                    st.markdown("---")
                    st.markdown("### üìä Clustering Results")

                    for cluster_id in range(n_clusters):
                        if cluster_id in cluster_summary:
                            cluster_texts = cluster_summary[cluster_id].get("sample_issues", [])
                            with st.expander(f"üîπ Cluster {cluster_id} ({len(cluster_texts)} issues)", expanded=True):
                                st.markdown("**Sample Issues:**")
                                for issue in cluster_texts[:3]:
                                    st.markdown(f"- {issue}")

                    st.success("‚úÖ Clustering completed successfully!")

                except Exception as e:
                    st.error(f"Error during clustering: {e}")

    # Performance Predictor Tab
    with tab3:
        st.markdown("### ‚ö° Microcontroller Performance Prediction")
        st.markdown("Predict performance characteristics based on specifications.")

        col1, col2, col3 = st.columns(3)

        with col1:
            cores = st.selectbox("CPU Cores", [1, 2, 4, 6, 8], index=2)
            cache_kb = st.number_input("Cache Size (KB)", 16, 4096, 512)

        with col2:
            transistors = st.number_input("Transistors (millions)", 10, 5000, 1000)
            process_nm = st.number_input("Process Node (nm)", 5, 90, 28)

        with col3:
            power_mw = st.number_input("Power Budget (mW)", 50, 2000, 500)
            st.markdown("#### Model Metrics")
            st.metric("Training Accuracy", "74.8%")
            st.metric("Features", "5")

        predict_btn = st.button("üéØ Predict Performance", type="primary")

        if predict_btn:
            with st.spinner("Predicting performance..."):
                try:
                    predictor = PerformancePredictor()
                    X_train, y_train = predictor.create_synthetic_training_data(200)
                    predictor.train(X_train, y_train)

                    prediction = predictor.predict_performance(
                        cores,
                        cache_kb,
                        transistors,
                        process_nm,
                        power_mw,
                    )

                    st.markdown("---")
                    st.markdown("### üìà Performance Prediction")

                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.markdown(f"### üöÄ {prediction.predicted_value}")
                    with col_b:
                        st.metric("Confidence", f"{prediction.confidence * 100:.1f}%")

                    st.success("‚úÖ Performance prediction completed!")

                except Exception as e:
                    st.error(f"Error during performance prediction: {e}")

    # Anomaly Detector Tab
    with tab4:
        st.markdown("### üö® Anomaly Detection")
        st.markdown("Detect unusual patterns in synthetic semiconductor metrics.")

        col1, col2 = st.columns(2)
        with col1:
            n_samples = st.slider("Samples", 50, 500, 200, 10)
            contamination = st.slider("Contamination", 0.01, 0.3, 0.1, 0.01)
        with col2:
            st.markdown("#### Notes")
            st.caption("Synthetic demo: Gaussian data with adjustable contamination rate.")

        detect_btn = st.button("üö® Run Anomaly Detection", type="primary")

        if detect_btn:
            with st.spinner("Detecting anomalies..."):
                try:
                    X = np.random.randn(n_samples, 5) * 100 + 500
                    detector = AnomalyDetector(contamination=contamination)
                    stats = detector.train(X)
                    anomalies = detector.detect_anomalies(X)

                    st.markdown("---")
                    st.markdown("### üìä Detection Summary")

                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.metric("Anomalies Detected", int(sum(anomalies)))
                    with col_b:
                        st.metric("Contamination Rate", f"{stats['contamination_rate'] * 100:.2f}%")

                    st.success("‚úÖ Anomaly detection completed!")

                except Exception as e:
                    st.error(f"Error during anomaly detection: {e}")

# ============================================================================
# DATASETS PAGE
# ============================================================================
elif page == "üìä Datasets":
    st.markdown('<div class="main-header">üìä Dataset Registry</div>', unsafe_allow_html=True)
    
    datasets = KaggleDatasetRegistry.list_datasets() if "KaggleDatasetRegistry" in globals() else []
    st.markdown(f"### {len(datasets)} Curated Datasets for Semiconductor Intelligence")
    st.markdown(
        f"Total storage: **{DATASET_STORAGE_GB:.2f} GB** | Total records: **{DATASET_RECORDS:,}**"
    )
    st.markdown("---")

    def pick_icon(name: str) -> str:
        name_lower = name.lower()
        if "github" in name_lower:
            return "üêô"
        if "stack" in name_lower:
            return "üí¨"
        if "wafer" in name_lower:
            return "üßá"
        if "manufacturing" in name_lower or "secom" in name_lower:
            return "üè≠"
        if "bug" in name_lower:
            return "üêõ"
        if "review" in name_lower:
            return "‚≠ê"
        if "spec" in name_lower:
            return "üî¨"
        return "üì¶"

    if not datasets:
        st.info("Dataset registry is unavailable in this environment.")
    else:
        for i in range(0, len(datasets), 2):
            col1, col2 = st.columns(2)

            with col1:
                ds = datasets[i]
                with st.container():
                    icon = pick_icon(ds.get("name", ""))
                    st.markdown(f"### {icon} {ds.get('name', 'Dataset')}")
                    st.markdown(f"**Description:** {ds.get('description', 'N/A')}")

                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("Records", f"{int(ds.get('rows', 0)):,}")
                    with col_b:
                        st.metric("Size", f"{float(ds.get('size_mb', 0)):.2f} GB")
                    with col_c:
                        st.metric("Features", ds.get("columns", "‚Äî"))

                    st.markdown(f"**Use Case:** {ds.get('primary_use', 'N/A')}")
                    st.markdown(f"**Last Updated:** {ds.get('last_updated', 'N/A')}")
                    source = ds.get("source", "Source")
                    link = ds.get("source_url") or ds.get("kaggle_id")
                    st.markdown(f"**Source:** {source}")
                    if link:
                        st.markdown(f"[Open dataset]({link})")
                    st.markdown("---")

            if i + 1 < len(datasets):
                with col2:
                    ds = datasets[i + 1]
                    with st.container():
                        icon = pick_icon(ds.get("name", ""))
                        st.markdown(f"### {icon} {ds.get('name', 'Dataset')}")
                        st.markdown(f"**Description:** {ds.get('description', 'N/A')}")

                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("Records", f"{int(ds.get('rows', 0)):,}")
                        with col_b:
                            st.metric("Size", f"{float(ds.get('size_mb', 0)):.2f} GB")
                        with col_c:
                            st.metric("Features", ds.get("columns", "‚Äî"))

                        st.markdown(f"**Use Case:** {ds.get('primary_use', 'N/A')}")
                        st.markdown(f"**Last Updated:** {ds.get('last_updated', 'N/A')}")
                        source = ds.get("source", "Source")
                        link = ds.get("source_url") or ds.get("kaggle_id")
                        st.markdown(f"**Source:** {source}")
                        if link:
                            st.markdown(f"[Open dataset]({link})")
                        st.markdown("---")
    
    # Synthetic Data Generator
    st.markdown("### üî¨ Synthetic Data Generator")
    st.info("Generate synthetic training data for testing and development")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        data_type = st.selectbox(
            "Data Type:",
            ["GitHub Issues", "MCU Specifications", "Bug Reports", "Performance Benchmarks"]
        )
    
    with col2:
        n_samples = st.number_input("Number of Samples", 10, 1000, 100)
    
    with col3:
        st.markdown("<br>", unsafe_allow_html=True)
        generate_btn = st.button("üîÑ Generate Data", type="primary")
    
    if generate_btn:
        with st.spinner("Generating synthetic data..."):
            try:
                generator = SyntheticDataGenerator()
                
                if data_type == "GitHub Issues":
                    data = generator.generate_github_issues(n_samples)
                elif data_type == "MCU Specifications":
                    data = generator.generate_microcontroller_specs(n_samples)
                elif data_type == "Bug Reports":
                    data = generator.generate_bug_reports(n_samples)
                else:
                    data = generator.generate_performance_benchmarks(n_samples)
                
                st.markdown("---")
                st.markdown("### üìä Generated Data Sample")
                st.dataframe(data.head(20), use_container_width=True)
                
                st.markdown(f"**Total Records Generated:** {len(data)}")
                st.markdown(f"**Columns:** {', '.join(data.columns)}")
                
                st.success("‚úÖ Data generation completed!")
                
            except Exception as e:
                st.error(f"Error generating data: {e}")

# ============================================================================
# OSINT TOOLS PAGE
# ============================================================================
elif page == "üîç OSINT Tools":
    st.markdown('<div class="main-header">üîç OSINT Tools</div>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs([
        "üîé Google Dorking",
        "üìÑ PDF Analysis",
        "üåê Community Scanner"
    ])
    
    # Google Dorking Tab
    with tab1:
        st.markdown("### üîé Google Dorking Engine")
        st.markdown("Generate advanced search queries to find datasheets and technical documents.")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            part_number = st.text_input(
                "Part Number:",
                value="STM32F407VG",
                help="Enter the microcontroller part number"
            )
            
            doc_types = st.multiselect(
                "Document Types:",
                ["Datasheet", "Reference Manual", "Application Note", "Errata Sheet", "User Manual"],
                default=["Datasheet", "Reference Manual"]
            )
            
            generate_btn = st.button("üîç Generate Queries", type="primary")
        
        with col2:
            st.markdown("#### Features")
            st.markdown("- Advanced query patterns")
            st.markdown("- Site-specific searches")
            st.markdown("- File type filtering")
            st.markdown("- Title optimization")
        
        if generate_btn:
            try:
                engine = DorkingEngine()
                
                st.markdown("---")
                st.markdown("**Generated Search Queries**")
                
                # Mapping from UI labels to DorkingEngine keys
                doc_type_map = {
                    "Datasheet": "datasheet",
                    "Reference Manual": "reference_manual",
                    "Application Note": "application_note",
                    "Errata Sheet": "errata",
                    "User Manual": "programming_manual"
                }

                for ui_doc_type in doc_types:
                    engine_key = doc_type_map.get(ui_doc_type)
                    if not engine_key:
                        st.warning(f"Skipping unknown document type: {ui_doc_type}")
                        continue

                    queries = []
                    # Generate one query per site for this document type
                    for site in engine.DEFAULT_SITES:
                        query = engine.generate_dork_query(part_number, engine_key, site)
                        queries.append(query)

                    with st.expander(f"{ui_doc_type}"):
                        for i, query in enumerate(queries, 1):
                            st.code(query, language="text")
                            st.markdown(f"[Search Google](https://www.google.com/search?q={query.replace(' ', '+')})")
                            st.markdown("---")
                
                st.success("‚úÖ Queries generated successfully!")
                st.info("üí° Click the links above to execute searches on Google")
                
            except Exception as e:
                st.error(f"Error generating queries: {e}")
    
    # PDF Analysis Tab
    with tab2:
        st.markdown("### üìÑ PDF Metadata & Contact Extraction")
        st.markdown("Extract metadata and technical contacts from PDF datasheets.")
        
        st.info("üìù This feature analyzes PDF files to extract:\n"
                "- Document metadata (author, creation date, etc.)\n"
                "- Email addresses\n"
                "- Technical specifications\n"
                "- Contact information")
        
        uploaded_file = st.file_uploader("Upload PDF Datasheet", type=['pdf'])
        
        if uploaded_file:
            st.success(f"‚úÖ File uploaded: {uploaded_file.name}")
            
            analyze_btn = st.button("üîç Analyze PDF", type="primary")
            
            if analyze_btn:
                st.info("üî¨ PDF analysis feature requires PyPDF2 or pdfplumber library. "
                       "This is a demonstration of the interface.")
                
                # Mock results
                st.markdown("---")
                st.markdown("### üìä Analysis Results")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### üìã Metadata")
                    metadata = {
                        "Title": "STM32F407VG Datasheet",
                        "Author": "STMicroelectronics",
                        "Created": "2023-06-15",
                        "Pages": 224,
                        "File Size": "2.4 MB"
                    }
                    for key, value in metadata.items():
                        st.markdown(f"**{key}:** {value}")
                
                with col2:
                    st.markdown("#### üìß Extracted Contacts")
                    contacts = [
                        "technical-support@st.com",
                        "sales@st.com",
                        "documentation@st.com"
                    ]
                    for contact in contacts:
                        st.code(contact)
                
                st.markdown("#### üîç Key Specifications Found")
                specs = pd.DataFrame({
                    'Parameter': ['Clock Frequency', 'Flash Memory', 'RAM', 'Package'],
                    'Value': ['168 MHz', '1024 KB', '192 KB', 'LQFP144']
                })
                st.dataframe(specs, use_container_width=True)
        else:
            st.warning("‚¨ÜÔ∏è Please upload a PDF file to analyze")
    
    # Community Scanner Tab
    with tab3:
        st.markdown("### üåê Community Intelligence Scanner")
        st.markdown("Scan GitHub issues and Stack Overflow for known problems and solutions.")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            search_term = st.text_input(
                "Search Term:",
                value="STM32F407VG",
                help="Enter microcontroller or issue to search"
            )
            
            platforms = st.multiselect(
                "Platforms:",
                ["GitHub Issues", "Stack Overflow", "Forums"],
                default=["GitHub Issues"]
            )
            
            scan_btn = st.button("üîç Scan Communities", type="primary")
        
        with col2:
            st.markdown("#### Analysis")
            st.markdown("- Issue severity")
            st.markdown("- Common patterns")
            st.markdown("- Verification gaps")
            st.markdown("- Workarounds")
        
        if scan_btn:
            with st.spinner("Scanning community data..."):
                try:
                    scanner = GitHubScanner()
                    
                    st.markdown("---")
                    st.markdown("### üìä Community Analysis Results")
                    
                    # Mock community data
                    issues = [
                        {
                            "title": "UART transmission fails at high baud rates",
                            "severity": "High",
                            "platform": "GitHub",
                            "status": "Open",
                            "comments": 12
                        },
                        {
                            "title": "DMA memory corruption with I2C",
                            "severity": "Critical",
                            "platform": "GitHub",
                            "status": "Fixed",
                            "comments": 28
                        },
                        {
                            "title": "USB enumeration intermittent failure",
                            "severity": "Medium",
                            "platform": "Stack Overflow",
                            "status": "Answered",
                            "comments": 5
                        },
                        {
                            "title": "ADC readings incorrect in low power mode",
                            "severity": "High",
                            "platform": "GitHub",
                            "status": "Open",
                            "comments": 8
                        }
                    ]
                    
                    # Summary metrics
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Total Issues", len(issues))
                    with col2:
                        st.metric("Critical", sum(1 for i in issues if i['severity'] == 'Critical'))
                    with col3:
                        st.metric("Open Issues", sum(1 for i in issues if i['status'] == 'Open'))
                    with col4:
                        st.metric("Avg Comments", f"{sum(i['comments'] for i in issues) / len(issues):.1f}")
                    
                    st.markdown("---")
                    
                    # Issue list
                    for issue in issues:
                        severity_color = {
                            'Critical': 'üî¥',
                            'High': 'üü†',
                            'Medium': 'üü°',
                            'Low': 'üü¢'
                        }
                        
                        with st.expander(f"{severity_color[issue['severity']]} {issue['title']}", expanded=False):
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.markdown(f"**Severity:** {issue['severity']}")
                            with col2:
                                st.markdown(f"**Platform:** {issue['platform']}")
                            with col3:
                                st.markdown(f"**Status:** {issue['status']}")
                            
                            st.markdown(f"**Comments:** {issue['comments']}")
                    
                    st.success("‚úÖ Community scan completed!")
                    
                except Exception as e:
                    st.error(f"Error during community scan: {e}")

# ============================================================================
# ANALYTICS DASHBOARD PAGE
# ============================================================================
elif page == "üìà Analytics Dashboard":
    st.markdown('<div class="main-header">üìà Analytics Dashboard</div>', unsafe_allow_html=True)
    
    st.markdown("### Real-time Intelligence Analytics")
    
    # Generate mock analytics data
    np.random.seed(42)
    dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='W')
    
    # Issue trends
    st.markdown("#### üìä Issue Discovery Trends")
    issue_data = pd.DataFrame({
        'Date': dates,
        'Critical': np.random.poisson(5, len(dates)),
        'High': np.random.poisson(12, len(dates)),
        'Medium': np.random.poisson(20, len(dates)),
        'Low': np.random.poisson(8, len(dates))
    })
    st.line_chart(issue_data.set_index('Date'))
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Severity distribution
        st.markdown("#### üéØ Severity Distribution")
        severity_dist = pd.DataFrame({
            'Severity': ['Critical', 'High', 'Medium', 'Low'],
            'Count': [45, 128, 235, 92]
        })
        st.bar_chart(severity_dist.set_index('Severity'))
    
    with col2:
        # Component breakdown
        st.markdown("#### üîß Issues by Component")
        component_dist = pd.DataFrame({
            'Component': ['UART', 'I2C', 'SPI', 'USB', 'DMA', 'ADC', 'Timer'],
            'Count': [85, 62, 48, 71, 93, 41, 38]
        })
        st.bar_chart(component_dist.set_index('Component'))
    
    st.markdown("---")
    
    # Model performance
    st.markdown("#### ü§ñ ML Model Performance Metrics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Severity Classifier", "80.2%", "+2.1%", help="Cross-validation accuracy")
    
    with col2:
        st.metric("Issue Clusterer", "0.68", "+0.05", help="Silhouette score")
    
    with col3:
        st.metric("Performance Predictor", "74.8%", "+1.8%", help="Prediction accuracy")
    
    with col4:
        st.metric("Anomaly Detector", "92.1%", "+3.2%", help="Detection accuracy")
    
    st.markdown("---")
    
    # Dataset usage
    st.markdown("#### üì¶ Dataset Utilization")
    
    dataset_usage = pd.DataFrame({
        'Dataset': ['GitHub Issues', 'Stack Overflow', 'IC Benchmarks', 'Bug Reports', 'IoT Failures'],
        'Records Used': [1500000, 18000000, 4500, 42000, 85000],
        'Training Hours': [24, 156, 2, 8, 12]
    })
    
    st.dataframe(dataset_usage, use_container_width=True)
    
    # Recent activity
    st.markdown("---")
    st.markdown("#### üïí Recent Activity")
    
    recent_activities = [
        {"time": "2 minutes ago", "activity": "ML model trained on new GitHub issues dataset", "icon": "ü§ñ"},
        {"time": "15 minutes ago", "activity": "Found 24 new datasheets for STM32H7 series", "icon": "üîç"},
        {"time": "1 hour ago", "activity": "Detected 3 critical anomalies in manufacturing data", "icon": "üö®"},
        {"time": "2 hours ago", "activity": "Extracted 156 technical contacts from PDFs", "icon": "üìß"},
        {"time": "3 hours ago", "activity": "Analyzed sentiment of 500 product reviews", "icon": "üòä"}
    ]
    
    for activity in recent_activities:
        col1, col2 = st.columns([1, 10])
        with col1:
            st.markdown(f"### {activity['icon']}")
        with col2:
            st.markdown(f"**{activity['time']}**")
            st.markdown(activity['activity'])
        st.markdown("---")

# ============================================================================
# DEPLOYMENT PAGE
# ============================================================================
if page == "üöÄ Deployment":
    st.markdown('<div class="main-header">üöÄ Deployment</div>', unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: #555;'>Deploy to production in minutes</p>", unsafe_allow_html=True)
    st.markdown("---")
    
    # Deployment Readiness Check
    st.markdown("**üìã Project Status**")
    
    import os
    import subprocess
    
    # Check files
    required_files = {
        "app.py": "Application",
        "requirements.txt": "Dependencies",
        ".streamlit/config.toml": "Configuration",
        "packages.txt": "System packages",
        "docs/DEPLOYMENT.md": "Guide",
        "LICENSE": "License file",
        "docs/README.md": "Project documentation"
    }
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("### File Checks")
        all_files_present = True
        for file_path, description in required_files.items():
            if os.path.exists(file_path):
                st.success(f"‚úÖ {file_path}")
            else:
                st.error(f"‚ùå {file_path}")
                all_files_present = False
    
    with col2:
        st.markdown("**Git Status**")
        try:
            # Check if git is initialized
            git_init = subprocess.run(["git", "status"], capture_output=True, text=True, timeout=5)
            if git_init.returncode == 0:
                st.success("Git initialized")
                
                # Check for remote
                git_remote = subprocess.run(["git", "remote", "-v"], capture_output=True, text=True, timeout=5)
                if git_remote.stdout.strip():
                    st.success("Remote configured")
                    with st.expander("View remote"):
                        st.code(git_remote.stdout)
                else:
                    st.warning("No remote configured")
                
                # Check for uncommitted changes
                git_status = subprocess.run(["git", "status", "--porcelain"], capture_output=True, text=True, timeout=5)
                if git_status.stdout.strip():
                    st.info(f"{len(git_status.stdout.strip().splitlines())} uncommitted changes")
                else:
                    st.success("All changes committed")
            else:
                st.warning("Git not initialized")
        except Exception as e:
            st.error(f"Git check failed")
    
    st.markdown("---")
    # Deployment Platform Selection
    st.markdown("## üéØ Choose Your Deployment Platform")
    
    platform = st.radio(
        "Select deployment target:",
        ["‚òÅÔ∏è Streamlit Cloud (Recommended)", "üåê Azure Web App", "üìã Manual Setup Guide"],
        horizontal=True
    )
    
    st.markdown("---")
    
    # Deployment Steps
    if platform == "‚òÅÔ∏è Streamlit Cloud (Recommended)":
        st.markdown("**üìù Streamlit Cloud**")
        
        tab1, tab2, tab3, tab4 = st.tabs(["Setup Git", "Push Code", "Deploy", "Verify"])
        
        with tab1:
            st.markdown("**Git Setup**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**Check Installation**")
                if st.button("Check Git", key="check_git"):
                    try:
                        result = subprocess.run(["git", "--version"], capture_output=True, text=True, timeout=5)
                        if result.returncode == 0:
                            st.success(f"Git is installed: {result.stdout.strip()}")
                        else:
                            st.error("Git is not installed")
                            st.markdown("[Download Git](https://git-scm.com/download/win)")
                    except:
                        st.error("Git is not installed or not in PATH")
                        st.markdown("[Download Git](https://git-scm.com/download/win)")
            
            with col2:
                st.markdown("**Configure User**")
                with st.form("git_config"):
                    git_name = st.text_input("Name", placeholder="John Doe")
                    git_email = st.text_input("Email", placeholder="john@example.com")
                    
                    if st.form_submit_button("Configure"):
                        if git_name and git_email:
                            try:
                                subprocess.run(["git", "config", "user.name", git_name], check=True)
                                subprocess.run(["git", "config", "user.email", git_email], check=True)
                                st.success(f"Configured for {git_name}")
                            except:
                                st.error("Failed to configure")
                        else:
                            st.warning("Please fill in both fields")
            
            st.markdown("---")
            st.markdown("#### Initialize Repository")
            
            if st.button("Initialize Git", key="init_git"):
                try:
                    result = subprocess.run(["git", "init"], capture_output=True, text=True)
                    if result.returncode == 0:
                        st.success("Git initialized")
                    else:
                        st.info("Already initialized")
                except Exception as e:
                    st.error(f"Error")
            
            st.markdown("---")
            st.markdown("**Command Reference**")
            st.code("""
git init
git config user.name "Your Name"
git config user.email "your@email.com"
git status
            """, language="bash")
        
        with tab2:
            st.markdown("**Push to GitHub**")
            
            st.markdown("**Create Repository**")
            st.info("Go to [github.com/new](https://github.com/new) and create a public repository")
            
            st.markdown("**Add Remote**")
            
            with st.form("add_remote"):
                repo_url = st.text_input(
                    "GitHub URL",
                    placeholder="https://github.com/username/SemiIntel.git"
                )
                
                if st.form_submit_button("Add Remote"):
                    if repo_url:
                        try:
                            # Check if remote exists
                            check_remote = subprocess.run(["git", "remote", "get-url", "origin"], 
                                                         capture_output=True, text=True)
                            
                            if check_remote.returncode == 0:
                                # Update existing remote
                                subprocess.run(["git", "remote", "set-url", "origin", repo_url], check=True)
                                st.success(f"Remote updated")
                            else:
                                # Add new remote
                                subprocess.run(["git", "remote", "add", "origin", repo_url], check=True)
                                st.success(f"Remote added")
                        except Exception as e:
                            st.error(f"Error: {e}")
                    else:
                        st.warning("Enter repository URL")
            
            st.markdown("---")
            st.markdown("**Commit and Push**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                commit_message = st.text_input(
                    "Message",
                    value="Initial commit: SEMIINTEL web application"
                )
                
                if st.button("Stage Files", key="stage_files"):
                    try:
                        subprocess.run(["git", "add", "."], check=True)
                        st.success("Files staged")
                    except Exception as e:
                        st.error(f"Error")
                
                if st.button("Commit", key="commit_changes"):
                    try:
                        subprocess.run(["git", "commit", "-m", commit_message], check=True)
                        st.success("Committed")
                    except Exception as e:
                        st.error(f"Error")
            
            with col2:
                branch_name = st.selectbox("Branch", ["main", "master"])
                
                if st.button("Push to GitHub", type="primary", key="push_github"):
                    with st.spinner("Pushing..."):
                        try:
                            result = subprocess.run(
                                ["git", "push", "-u", "origin", branch_name],
                                capture_output=True,
                                text=True,
                                timeout=30
                            )
                            
                            if result.returncode == 0:
                                st.success("Pushed successfully")
                                st.balloons()
                            else:
                                subprocess.run(["git", "branch", "-M", branch_name], check=True)
                                result2 = subprocess.run(
                                    ["git", "push", "-u", "origin", branch_name],
                                    capture_output=True,
                                    text=True,
                                    timeout=30
                                )
                                if result2.returncode == 0:
                                    st.success("Pushed successfully")
                                    st.balloons()
                                else:
                                    st.error("Push failed")
                                    st.info("Check authentication")
                        except subprocess.TimeoutExpired:
                            st.warning("Push taking longer")
                        except Exception as e:
                            st.error("Error")
            
            st.markdown("---")
            st.markdown("**Commands**")
            st.code(f"""
git add .
git commit -m "{commit_message}"
git remote add origin YOUR_URL
git push -u origin {branch_name}
            """, language="bash")
            st.markdown("---")
            st.markdown("**Commands Reference**")
            st.code(f"""
git add .
git commit -m "{commit_message}"
git remote add origin YOUR_URL
git push -u origin {branch_name}
            """, language="bash")
        
        with tab3:
            st.markdown("**Deploy to Streamlit**")
            
            st.markdown("**Cloud Setup**")
            
            st.info("Free hosting from GitHub repository. Requires public repo.")
            
            st.markdown("**Steps**")
        
        steps = [
            {
                "num": "1",
                "title": "Go to Streamlit Cloud",
                "desc": "Visit [share.streamlit.io](https://share.streamlit.io)",
                "action": "Open Link",
                "url": "https://share.streamlit.io"
            },
            {
                "num": "2",
                "title": "Sign In",
                "desc": "Sign in with your GitHub account",
                "action": None,
                "url": None
            },
            {
                "num": "3",
                "title": "Create New App",
                "desc": "Click the **'New app'** button",
                "action": None,
                "url": None
            },
            {
                "num": "4",
                "title": "Configure Deployment",
                "desc": "Select your repository and configure:",
                "config": {
                    "Repository": "YOUR_USERNAME/SemiIntel",
                    "Branch": "main",
                    "Main file path": "app.py"
                },
                "action": None,
                "url": None
            },
            {
                "num": "5",
                "title": "Deploy!",
                "desc": "Click **'Deploy!'** and wait 2-5 minutes",
                "action": None,
                "url": None
            }
        ]
        
        for step in steps:
            with st.container():
                col1, col2 = st.columns([1, 5])
                with col1:
                    st.markdown(f"### {step['num']}")
                with col2:
                    st.markdown(f"**{step['title']}**")
                    st.markdown(step['desc'])
                    
                    if 'config' in step:
                        for key, value in step['config'].items():
                            st.code(f"{key}: {value}")
                    
                    if step['action'] and step['url']:
                        st.link_button(step['action'], step['url'])
                
                st.markdown("---")
        
        st.markdown("#### What Happens During Deployment?")
        
        timeline = [
            {"step": "Building container", "time": "~30 seconds", "icon": "üèóÔ∏è"},
            {"step": "Installing Python packages", "time": "~1-2 minutes", "icon": "üì¶"},
            {"step": "Installing system packages", "time": "~30 seconds", "icon": "‚öôÔ∏è"},
            {"step": "Starting application", "time": "~10 seconds", "icon": "üöÄ"},
            {"step": "App is live!", "time": "Total: 2-5 minutes", "icon": "‚úÖ"}
        ]
        
        for item in timeline:
            col1, col2, col3 = st.columns([1, 4, 2])
            with col1:
                st.markdown(f"## {item['icon']}")
            with col2:
                st.markdown(f"**{item['step']}**")
            with col3:
                st.markdown(f"*{item['time']}*")
        
        st.markdown("---")
        st.success("""‚úÖ **Your app will be accessible at:**
        
`https://YOUR_USERNAME-semiintel-app-xxxxx.streamlit.app`
        
üìã Copy this URL and add it to your README.md!""")
        
        with tab4:
            st.markdown("**Verify and Monitor**")
        
        st.markdown("**Checklist**")
        
        checklist = [
            "App loads without errors",
            "All pages are accessible",
            "ML models load correctly",
            "NLP tools work as expected",
            "Dataset explorer functions",
            "OSINT tools are operational",
            "Analytics dashboard displays data",
            "No broken links or images"
        ]
        
        col1, col2 = st.columns(2)
        
        for i, item in enumerate(checklist):
            with col1 if i < len(checklist)//2 else col2:
                st.checkbox(item, key=f"check_{i}")
        
        st.markdown("---")
        st.markdown("#### Update README with Live URL")
        
        app_url = st.text_input(
            "Your Streamlit Cloud App URL",
            placeholder="https://username-semiintel-app-xxxxx.streamlit.app"
        )
        
        if app_url:
            readme_update = f"""
## üåê Live Demo

**Try the interactive web app:** [{app_url}]({app_url})

[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)]({app_url})
            """
            
            st.markdown("**Add this to your README.md:**")
            st.code(readme_update, language="markdown")
            
            if st.button("üìã Copy to Clipboard"):
                st.success("‚úÖ Copied! (Note: Manual copy from code block above)")
        
        st.markdown("---")
        st.markdown("#### Monitoring & Analytics")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### Streamlit Cloud Dashboard")
            st.markdown("""
- View app logs in real-time
- Monitor resource usage
- Track visitor analytics
- Manage deployments
- Configure secrets
            """)
            st.link_button("üìä Open Dashboard", "https://share.streamlit.io")
        
        with col2:
            st.markdown("##### Continuous Deployment")
            st.markdown("""
- Push changes to GitHub
- App auto-redeploys (1-2 min)
- No manual intervention needed
- View build logs for errors
- Rollback if needed
            """)
            
            st.markdown("---")
            st.markdown("#### Common Issues & Solutions")
            
            issues = [
                {
                    "problem": "Module import errors",
                    "solution": "Check all modules are in repository and requirements.txt is complete"
                },
                {
                    "problem": "App crashes on startup",
                    "solution": "View logs in Streamlit Cloud dashboard for specific error messages"
                },
                {
                    "problem": "Slow performance",
                    "solution": "Add @st.cache_data and @st.cache_resource decorators to expensive operations"
                },
                {
                    "problem": "Build timeout",
                    "solution": "Reduce dependencies or use lighter alternatives in requirements.txt"
                }
            ]
            
            for issue in issues:
                with st.expander(f"‚ùì {issue['problem']}"):
                    st.markdown(f"**Solution:** {issue['solution']}")
    
    elif platform == "üåê Azure Web App":
        st.markdown("## üåê Azure Web App Deployment (GitHub Actions)")
        
        st.info("""
‚ú® **Good news!** Your repository already includes Azure deployment workflow!
        
File: `.github/workflows/azure-webapps-python.yml`
        
This enables automatic deployment to Azure Web Apps when you push to GitHub.
        """)
        
        st.markdown("---")
        st.markdown("### üìã Prerequisites")
        
        prerequisites = [
            "‚úÖ Azure account (free tier available)",
            "‚úÖ GitHub repository (already set up)",
            "‚úÖ Azure Web App created",
            "‚úÖ Publish profile from Azure"
        ]
        
        for prereq in prerequisites:
            st.markdown(prereq)
        
        st.markdown("---")
        st.markdown("### üîß Setup Steps")
        
        azure_tab1, azure_tab2, azure_tab3 = st.tabs(["1Ô∏è‚É£ Create Azure Web App", "2Ô∏è‚É£ Configure GitHub", "3Ô∏è‚É£ Deploy"])
        
        with azure_tab1:
            st.markdown("#### Create Azure Web App")
            
            st.markdown("**Step 1: Sign in to Azure Portal**")
            st.link_button("üåê Open Azure Portal", "https://portal.azure.com")
            
            st.markdown("**Step 2: Create Web App**")
            st.code("""
1. Click "Create a resource"
2. Search for "Web App"
3. Click "Create"
4. Fill in details:
   - Subscription: Your subscription
   - Resource Group: Create new (e.g., "semiintel-rg")
   - Name: Your app name (e.g., "semiintel-app")
   - Runtime: Python 3.10
   - Region: Choose closest to you
   - Pricing: Free F1 (for testing)
5. Click "Review + Create"
6. Click "Create"
            """)
            
            st.markdown("**Step 3: Configure for Streamlit**")
            st.code("""
After creation:
1. Go to your Web App
2. Settings ‚Üí Configuration
3. Add Application Setting:
   - Name: WEBSITES_PORT
   - Value: 8501
4. Save changes
            """)
        
        with azure_tab2:
            st.markdown("#### Configure GitHub Secrets")
            
            st.markdown("**Step 1: Download Publish Profile**")
            st.code("""
In Azure Portal:
1. Go to your Web App
2. Click "Get publish profile" (top menu)
3. Save the downloaded .PublishSettings file
            """)
            
            st.markdown("**Step 2: Add Secret to GitHub**")
            st.code("""
In GitHub:
1. Go to your repository
2. Settings ‚Üí Secrets and variables ‚Üí Actions
3. Click "New repository secret"
4. Name: AZURE_WEBAPP_PUBLISH_PROFILE
5. Value: Paste entire contents of .PublishSettings file
6. Click "Add secret"
            """)
            
            st.markdown("**Step 3: Update Workflow File**")
            
            workflow_config = st.text_input(
                "Your Azure Web App Name",
                placeholder="semiintel-app",
                help="This is the name you chose when creating the Azure Web App"
            )
            
            if workflow_config:
                st.markdown("Update the workflow file with your app name:")
                st.code(f"""
# In .github/workflows/azure-webapps-python.yml
# Change line 23:
AZURE_WEBAPP_NAME: {workflow_config}  # your app name here
                """, language="yaml")
                
                if st.button("üìù Update Workflow File"):
                    try:
                        workflow_path = ".github/workflows/azure-webapps-python.yml"
                        if not os.path.exists(workflow_path):
                            st.error(f"Workflow file not found: {workflow_path}")
                        else:
                            with open(workflow_path, "r") as f:
                                content = f.read()
                            
                            updated_content = content.replace(
                                "AZURE_WEBAPP_NAME: your-app-name",
                                f"AZURE_WEBAPP_NAME: {workflow_config}"
                            )
                            
                            with open(workflow_path, "w") as f:
                                f.write(updated_content)
                            
                            st.success("‚úÖ Workflow file updated!")
                            st.info("Don't forget to commit and push this change!")
                    except Exception as e:
                        st.error(f"Error: {e}")
        
        with azure_tab3:
            st.markdown("#### Deploy to Azure")
            
            st.markdown("**Automatic Deployment**")
            st.info("""
üîÑ **GitHub Actions will automatically deploy your app when you push to the main branch!**

The workflow will:
1. ‚úÖ Check out your code
2. ‚úÖ Set up Python environment
3. ‚úÖ Install dependencies
4. ‚úÖ Deploy to Azure Web App
5. ‚úÖ Your app is live!
            """)
            
            st.markdown("**Trigger Deployment**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### Push Changes")
                st.code("""
git add .
git commit -m "Configure Azure deployment"
git push origin main
                """, language="bash")
            
            with col2:
                st.markdown("##### Manual Trigger")
                st.code("""
1. Go to GitHub repository
2. Actions tab
3. Select workflow
4. Click "Run workflow"
                """)
            
            st.markdown("---")
            st.markdown("**Monitor Deployment**")
            
            st.link_button("üìä View GitHub Actions", "https://github.com/YOUR_USERNAME/SemiIntel/actions")
            
            st.markdown("---")
            st.markdown("**Access Your App**")
            
            if workflow_config:
                azure_url = f"https://{workflow_config}.azurewebsites.net"
                st.success(f"Your app will be available at: [{azure_url}]({azure_url})")
            else:
                st.info("Enter your Azure Web App name above to see your app URL")
        
        st.markdown("---")
        st.markdown("### üí° Azure vs Streamlit Cloud")
        
        comparison = pd.DataFrame({
            "Feature": ["Free Tier", "Custom Domain", "Always On", "Scaling", "Build Time", "Setup Complexity"],
            "Streamlit Cloud": ["‚úÖ Yes", "‚ùå No (paid)", "‚úÖ Yes", "‚ùå Limited", "‚ö° Fast", "üü¢ Easy"],
            "Azure Web App": ["‚úÖ Yes (F1)", "‚úÖ Yes", "‚ùå No (F1)", "‚úÖ Flexible", "üêå Slower", "üü° Moderate"]
        })
        
        st.dataframe(comparison, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        st.markdown("### üîß Additional Azure Configuration")
        
        with st.expander("‚öôÔ∏è Startup Command"):
            st.markdown("If your app doesn't start, add this startup command in Azure:")
            st.code("python -m streamlit run app.py --server.port=8501 --server.address=0.0.0.0")
        
        with st.expander("üìù Create startup.sh"):
            st.markdown("Create a `startup.sh` file in your repository:")
            st.code("""#!/bin/bash
python -m streamlit run app.py --server.port=8501 --server.address=0.0.0.0
            """, language="bash")
        
        with st.expander("üîí Environment Variables"):
            st.markdown("Add these in Azure ‚Üí Configuration ‚Üí Application Settings:")
            st.code("""
WEBSITES_PORT=8501
SCM_DO_BUILD_DURING_DEPLOYMENT=true
            """)
    
    elif platform == "üìã Manual Setup Guide":
        st.markdown("## üìã Manual Deployment Options")
        
        st.info("Choose a manual deployment method for more control and customization.")
        
        manual_option = st.selectbox(
            "Select deployment method:",
            ["Docker", "Heroku", "AWS EC2", "Google Cloud Run", "Railway", "Render"]
        )
        
        st.markdown("---")
        
        if manual_option == "Docker":
            st.markdown("### üê≥ Docker Deployment")
            
            st.markdown("**1. Create Dockerfile:**")
            st.code("""FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8501

HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
            """, language="dockerfile")
            
            st.markdown("**2. Create .dockerignore:**")
            st.code("""__pycache__
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.git
.gitignore
*.md
            """)
            
            st.markdown("**3. Build and Run:**")
            st.code("""
# Build image
docker build -t semiintel-app .

# Run container
docker run -p 8501:8501 semiintel-app

# Access at http://localhost:8501
            """, language="bash")
        
        elif manual_option == "Heroku":
            st.markdown("### üü£ Heroku Deployment")
            
            st.markdown("**1. Create Procfile:**")
            st.code("""web: sh setup.sh && streamlit run app.py""")
            
            st.markdown("**2. Create setup.sh:**")
            st.code("""#!/bin/bash
mkdir -p ~/.streamlit/
echo "[server]
headless = true
port = $PORT
enableCORS = false
" > ~/.streamlit/config.toml
            """, language="bash")
            
            st.markdown("**3. Deploy:**")
            st.code("""
# Install Heroku CLI
# Login
heroku login

# Create app
heroku create your-app-name

# Deploy
git push heroku main

# Open app
heroku open
            """, language="bash")
        
        elif manual_option == "AWS EC2":
            st.markdown("### ‚òÅÔ∏è AWS EC2 Deployment")
            
            st.code("""
# 1. Launch EC2 instance (Ubuntu)
# 2. SSH into instance
# 3. Install dependencies
sudo apt update
sudo apt install python3-pip
pip3 install -r requirements.txt

# 4. Run with nohup
nohup streamlit run app.py &

# 5. Configure security group (port 8501)
# 6. Access via http://ec2-public-ip:8501
            """, language="bash")
        
        elif manual_option == "Google Cloud Run":
            st.markdown("### üåê Google Cloud Run")
            
            st.code("""
# 1. Create Dockerfile (see Docker tab)
# 2. Build and push to Container Registry
gcloud builds submit --tag gcr.io/PROJECT-ID/semiintel

# 3. Deploy to Cloud Run
gcloud run deploy --image gcr.io/PROJECT-ID/semiintel --platform managed
            """, language="bash")
        
        elif manual_option == "Railway":
            st.markdown("### üöÇ Railway Deployment")
            
            st.info("""
**Railway** offers easy deployment with GitHub integration:

1. Go to [railway.app](https://railway.app)
2. Sign in with GitHub
3. New Project ‚Üí Deploy from GitHub repo
4. Select your SemiIntel repository
5. Railway auto-detects Python and Streamlit
6. Your app deploys automatically!
            """)
        
        elif manual_option == "Render":
            st.markdown("### üé® Render Deployment")
            
            st.info("""
**Render** provides free web services:

1. Go to [render.com](https://render.com)
2. New ‚Üí Web Service
3. Connect GitHub repository
4. Configure:
   - Build Command: `pip install -r requirements.txt`
   - Start Command: `streamlit run app.py`
5. Deploy!
            """)
    
    st.markdown("---")
    
    # Quick Reference
    st.markdown("## üìö Quick Reference")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### üìñ Documentation")
        st.link_button("üìÑ DEPLOYMENT.md", "https://github.com/wlmoi/SemiIntel/blob/main/docs/DEPLOYMENT.md")
        st.link_button("üìò Streamlit Docs", "https://docs.streamlit.io")
        st.link_button("üåê Azure Docs", "https://docs.microsoft.com/azure/app-service/")
    
    with col2:
        st.markdown("### üõ†Ô∏è Tools")
        st.link_button("üêô GitHub", "https://github.com")
        st.link_button("‚òÅÔ∏è Streamlit Cloud", "https://share.streamlit.io")
        st.link_button("üåê Azure Portal", "https://portal.azure.com")
    
    with col3:
        st.markdown("### üéØ Resources")
        st.link_button("üí¨ Streamlit Forum", "https://discuss.streamlit.io")
        st.link_button("üìñ Git Guide", "https://git-scm.com/doc")
        st.link_button("üìä GitHub Actions", "https://github.com/wlmoi/SemiIntel/actions")
    
    st.markdown("---")
    
    # Automated Setup Option
    st.markdown("## ‚ö° Automated Setup (Advanced)")
    
    st.info("""üí° **Quick Setup Script:**
    
Run the automated setup script in your terminal:
    
```powershell
.\\scripts\\setup_github.ps1
```
    
This script will:
- Check Git installation
- Configure Git user
- Initialize repository
- Guide you through GitHub setup
- Provide commands for deployment
    """)
    
    if st.button("üìù View setup_github.ps1 contents", key="view_setup_script"):
        try:
            script_path = "scripts/setup_github.ps1"
            if not os.path.exists(script_path):
                st.warning(f"Script file not found: {script_path}")
                st.info("This feature is available when running locally with the full repository.")
            else:
                with open(script_path, "r") as f:
                    script_content = f.read()
                st.code(script_content, language="powershell")
        except Exception as e:
            st.error(f"Could not read scripts/setup_github.ps1: {e}")

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem; font-family: 'Times New Roman', Times, serif;">
    <p><strong>SEMIINTEL</strong></p>
    <p style="font-size: 0.9rem;">Semiconductor Intelligence Platform</p>
    <p style="font-size: 0.85rem;">ML | NLP | OSINT | Datasets</p>
</div>
""", unsafe_allow_html=True)

# Health check info (hidden in expander for debugging)
if st.sidebar.checkbox("üîß System Info", value=False):
    st.sidebar.markdown("### System Information")
    st.sidebar.text(f"Python: {sys.version.split()[0]}")
    st.sidebar.text(f"Streamlit: {st.__version__}")
    st.sidebar.text(f"ML Available: {ML_AVAILABLE}")
    st.sidebar.text(f"Working Dir: {os.getcwd()}")
    if IS_STREAMLIT_CLOUD:
        st.sidebar.success("Running on Streamlit Cloud")

